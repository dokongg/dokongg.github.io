<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Dokongg Blog</title>

  <link rel="stylesheet" href="/assets/css/style.css">
  <link rel="stylesheet" href="/assets/css/syntax-one-dark.css">
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Dokongg Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>
        <div class="trigger">
          <div>
            <div id="search" >
                <span id="searchform" method="post" action="/search/" class="">
    <div class="form-group">
        <input class="search-input" onkeyup="myFunc()" id="keyword" type="text" name="keyword" placeholder="Search..." />
    </div>
    <script src="/assets/js/jquery-3.6.0.min.js"></script>

    <script type="text/javascript">
        function myFunc() {
            var keyword = $("#keyword").val();

            if( keyword.trim() == '' ) {
              return;
            }
            if(event.keyCode == 13) {
                var url = encodeURIComponent(keyword);
                location.href = "/search?query=" + url;
            }
        }
    </script>
</span>

            </div>
          </div>
          
            <a class="page-link" href="/Algorithms/index">Algorithms</a>
          
            <a class="page-link" href="/CS/index">CS</a>
          
            <a class="page-link" href="/Java/index">Java</a>
          
            <a class="page-link" href="/Spring/index">Spring</a>
          
            <a class="page-link" href="/JPA/index">JPA</a>
          
            <a class="page-link" href="/ES/index">ES</a>
          
            <a class="page-link" href="/MSA/index">MSA</a>
          
        </div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h3 class="post-title p-name" itemprop="name headline">Part 1-4. 운영체제</h3>
    <p class="post-meta post-right"><time class="dt-published" datetime="2021-05-06T00:00:00+00:00" itemprop="datePublished">
        2021-05-06
      </time></p>
  </header>

  <div class="post-content e-content post-content-body" itemprop="articleBody">
    <ol>
  <li>
    <p><strong>프로세스와 스레드의 차이</strong> <br />
1.1. 프로세스(Process) <br />
1.2. 프로세스 제어 블록(PCB, Process Control Block) <br />
1.3. 스레드(Thread)</p>
  </li>
  <li>
    <p><strong>멀티 스레드</strong> <br />
2.1. 멀티 스레드의 장점 <br />
2.2. 멀티 스레드의 문제점 <br />
2.3. 멀티 스레드와 멀티 프로세스</p>
  </li>
  <li>
    <p><strong>스케줄러</strong> <br />
3.1. Queue의 종류 <br />
3.2. 장기 스테줄러 <br />
3.3. 단기 스케줄러 <br />
3.4. 중기 스케줄러</p>
  </li>
  <li>
    <p><strong>CPU 스케줄러</strong> <br />
4.1. FCFS(First Come First Served) <br />
4.2. SJF(Shortest Job First) <br />
4.3. SRTF(Shortest Remaining Time First) <br />
4.4. Priority Scheduling <br />
4.5. RR(Round Robin)</p>
  </li>
  <li>
    <p><strong>동기와 비동기의 차이</strong> <br />
5.1. Sync vs. Async <br />
5.2. Blocking I/O Model <br />
5.3. Non-Blocking I/O Model <br />
5.4. Asynchronous I/O Model</p>
  </li>
  <li>
    <p><strong>프로세스 동기화</strong> <br />
6.1. Critical Section(임계영역) <br />
6.2. Critical Section Problem(임계영역 문제) <br />
6.3. Critical Section Problem의 해결책</p>
  </li>
  <li>
    <p><strong>메모리 관리 전략</strong> <br />
7.1. 메모리 관리 배경 <br />
7.2. 메모리 단편화(Fragmentation) <br />
7.3. 메모리 단편화(Fragmentation) 문제 해결책</p>
  </li>
  <li>
    <p><strong>가상 메모리</strong> <br />
8.1. 가상 메모리 개발 배경 <br />
8.2. 가상 메모리가 하는 일 <br />
8.3. Demand Paging(요구 페이징) <br />
8.4. 페이지 교체 알고리즘</p>
  </li>
  <li>
    <p><strong>캐시의 지역성</strong> <br />
9.1. 캐시의 지역성 원리 <br />
9.2. Caching line</p>
  </li>
</ol>

<hr />

<h4 id="1-프로세스와-스레드의-차이"><strong>1. 프로세스와 스레드의 차이</strong></h4>

<h5 id="11-프로세스process"><strong>1.1. 프로세스(Process)</strong></h5>

<p>(1) 프로세스란?</p>

<ul>
  <li>실행 중인 프로그램</li>
  <li>디스크로부터 메모리에 적재되어 CPU의 할당을 받을수 있는 것</li>
  <li>운영체제로부터 주소 공간, 파일, 메모리 등을 할당받는다.</li>
</ul>

<p>(2) 프로세스의 구성</p>

<ul>
  <li>함수의 매개변수, 복귀주소와 로컬변수와 같은 임시자료를 갖는 프로세스 스택과 전역변수들을 수록하는 데이터 섹션을 포함</li>
  <li>프로세스 실행 중에 동적으로 할당되는 메모리인 힙을 포함</li>
</ul>

<h5 id="12-프로세스-제어블록pcb-process-control-block"><strong>1.2. 프로세스 제어블록(PCB, Process Control Block)</strong></h5>

<p>(1) PCB란?</p>

<ul>
  <li>특정 프로세스에 대한 중요한 정보를 저장하고 있는 운영체제의 자료구조</li>
</ul>

<p>(2) PCB의 역할</p>

<ul>
  <li>운영체제는 프로세스를 관리하기 위해 프로세스를 생성하는 것과 동시에 고유한 PCB를 생성한다.</li>
  <li>프로세스는 CPU의 할당을 받아 작업을 처리하다가 프로세스를 전환하는 일이 발생하면, 진행하던 작업을 저장한 다음 CPU를 반환해야 한다. 이 때, 작업하던 진행사항을 모두 PCB에 저장하게 된다. 그리고 다시 CPU를 할당받으면, PCB에 저장되어 있던 내용을 불러와 이전에 종료됐던 시점부터 다시 작업을 시작한다.</li>
</ul>

<p>(3) PCB에 저장되는 정보</p>

<ul>
  <li>프로세스 식별자(Process ID, PID): 프로세스 식별번호</li>
  <li>프로세스 상태: new/ready/running/waiting/ternimated 등의 상태를 저장</li>
  <li>프로그램 카운터: 프로세스가 다음에 실행할 명령어의 주소</li>
  <li>CPU 레지스터</li>
  <li>CPU 스케줄링 정보: 프로세스 우선순위, 스케줄 큐에 대한 포인터 등</li>
  <li>메모리 관리정보: 페이지 테이블 또는 세그먼트 테이블과 같은 정보를 포함</li>
  <li>입출력 상태정보: 프로세스에 할당된 입출력 장치들과 열린 파일 목록</li>
  <li>어카운팅 정보</li>
</ul>

<h5 id="13-스레드thread"><strong>1.3. 스레드(Thread)</strong></h5>

<p>(1) 스레드란?</p>

<ul>
  <li>프로세스의 실행 단위</li>
  <li>한 프로세스 내에서 동작하는 여러 실행 흐름</li>
  <li>프로세스 내 주소 공간이나 자원을 공유할 수 있다.</li>
  <li>스레드 ID, 프로그램 카운터, 레지스터 집합, 스택으로 구성
    <ul>
      <li>각자의 스레드는 독립적인 작업을 수행해야 하기 때문에 각자의 스택, PC 레지스터 값을 갖고 있다.</li>
    </ul>
  </li>
</ul>

<p>(2) 스레드의 역할</p>

<ul>
  <li>같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션, 열린 파일이나 신호와 같은 운영체제 자원들을 공유한다.</li>
</ul>

<p>(3) 멀티 스레딩</p>

<ul>
  <li>하나의 프로세스를 여러 개의 실행 단위로 구분하여, 자원을 공유하고 자원의 생성과 관리의 중복을 최소화하여 수행 능력을 향상시키는 것</li>
</ul>

<p>(4) 스레드마다 스택을 독립적으로 할당하는 이유</p>

<ul>
  <li>스택이란?
    <ul>
      <li>함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간</li>
      <li>스택 메모리 공간이 독립적이다 = 독립적인 함수 호출이 가능하며, 독립적인 실행 흐름이 추가된다.</li>
    </ul>
  </li>
  <li>스레드의 정의에 따라 독립적인 실행흐름을 추가하기 위한 최소조건이기 때문</li>
</ul>

<p>(5) 스레드마다 PC Register를 독립적으로 할당하는 이유</p>

<ul>
  <li>PC Register의 값은 스레드가 명령어를 어디까지 수행했는 지를 나타냄</li>
  <li>스레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당하기 때문에, 명령어를 연속적으로 수행하지 못한다. 따라서, 명령어를 어느 부분까지 수행했는지 기억할 필요가 있기 때문</li>
</ul>

<h4 id="2-멀티-스레드"><strong>2. 멀티 스레드</strong></h4>

<h5 id="21-멀티-스레딩의-장점"><strong>2.1. 멀티 스레딩의 장점</strong></h5>

<ul>
  <li>프로세스를 이용해 동시에 처리하던 일을 스레드로 구현하면, 메모리 공간과 시스템 자원의 소모가 줄어들게 된다.</li>
  <li>스레드 간 통신이 필요한 경우에도 별도의 자원을 이용하는 것이 아니라 전역 변수의 공간 또는 동적으로 할당된 공간인 Heap 영역을 이용하여 데이터를 주고 받을 수 있다(스레드 간 통신 방법은 프로세스 간 통신 방법보다 훨씬 간단하다).</li>
  <li>스레드의 Context switch는 프로세스의 Context switch와 달리 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다.
    <ul>
      <li>시스템의 처리율(throughput)이 향상되고 자원 소모가 줄어들며, 자연스럽게 프로그램의 응답 시간이 단축된다.</li>
    </ul>
  </li>
</ul>

<h5 id="22-멀티-스레딩의-문제점"><strong>2.2. 멀티 스레딩의 문제점</strong></h5>

<ul>
  <li>멀티 프로세스 기반으로 프로그래밍 할 때는 프로세스 간 공유하는 자원이 없기 때문에 동일한 자원에 접근하는 일이 없었다.</li>
  <li>멀티 스레딩은 서로 다른 프로세스가 데이터 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용 중인 변수나 자료구조에 접근했을 때, 엉뚱한 값을 가져오거나 이로 인해 수정하는 일이 발생한다.
    <ul>
      <li>동기화 작업이 필요: 동기화를 통해 작업 처리 순서를 컨트롤하고, 공유 자원에 접근하는 것을 컨트롤 하는 것</li>
    </ul>
  </li>
  <li>동기화 작업으로 인하여 과도한 락이 발생할 수 있다.</li>
</ul>

<h5 id="23-멀티-스레드와-멀티-프로세스"><strong>2.3. 멀티 스레드와 멀티 프로세스</strong></h5>

<table>
  <thead>
    <tr>
      <th style="text-align: center"> </th>
      <th style="text-align: left">멀티 스레드</th>
      <th style="text-align: left">멀티 프로세스</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">장점</td>
      <td style="text-align: left">멀티 프로세스보다 적은 메모리 공간을 차지하고 문맥전환이 빠르다.</td>
      <td style="text-align: left">하나의 프로세스가 죽어도 다른 프로세스에 영향이 없다.</td>
    </tr>
    <tr>
      <td style="text-align: center">단점</td>
      <td style="text-align: left">- 오류로 인해 하나의 스레드가 종료되면, 전체 스레드가 종료될 수 있다.<br />- 동기화 문제</td>
      <td style="text-align: left">멀티 스레드보다 많은 메모리 공간과 CPU 시간 차지</td>
    </tr>
  </tbody>
</table>

<h4 id="3-스케줄러"><strong>3. 스케줄러</strong></h4>

<h5 id="31-queue의-종류"><strong>3.1. Queue의 종류</strong></h5>

<p>: 프로세스를 스케줄링하기 위한 3가지 종류의 Queue</p>

<ul>
  <li>Job Queue: 현재 시스템 내에 있는 모든 프로세스의 집합</li>
  <li>Ready Queue: 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 집합</li>
  <li>Device Queue: Device I/O 작업을 대기하고 있는 프로세스의 집합</li>
</ul>

<h5 id="32-장기-스케줄러long-term-scheduler-or-job-scheduler"><strong>3.2. 장기 스케줄러(Long-term Scheduler or Job Scheduler)</strong></h5>

<p>(1) 메모리와 디스크 사이의 스케줄링 담당</p>

<ul>
  <li>메모리는 한정되어 있기 때문에 많은 프로세스가 한꺼번에 올라오는 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장된다. 이 pool에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 Ready Queue에 보낼 것인지 결정한다.</li>
</ul>

<p>(2) 프로세스에 memory 및 각종 resource 할당(admit) <br />
(3) 실행 중인 프로세스의 수(degree of multiprogramming) 제어 <br />
(4) 프로세스의 상태: new → ready(in memory)</p>

<h5 id="33-단기-스케줄러short-term-scheduler-or-cpu-scheduler"><strong>3.3. 단기 스케줄러(Short-term Scheduler or CPU Scheduler)</strong></h5>

<p>(1) CPU와 메모리 사이의 스케줄링을 담당 <br />
(2) Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running 시킬 것인지 결정 <br />
(3) 프로세스에 CPU를 할당(Scheduler dispatch) <br />
(4) 프로세스의 상태: ready → running → waiting → ready</p>

<h5 id="34-중기-스케줄러mid-term-scheduler-or-swapper"><strong>3.4. 중기 스케줄러(Mid-term Scheduler or Swapper)</strong></h5>

<p>(1) 여유공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄(Swapping) <br />
(2) 프로세스에게서 memory를 deallocate 한다. <br />
(3) 실행 중인 프로세스의 수(degree of multiprogramming) 제어 <br />
(4) 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절하는 스케줄러 <br />
(5) 프로세스의 상태: ready → suspend</p>

<blockquote>
  <p><em><strong>※ suspend(stopped) 상태</strong></em></p>

  <ul>
    <li>외부적인 이유로 프로세스의 수행이 정지된 상태로 메모리에서 내려간 상태</li>
    <li>프로세스 전부가 디스크로 swap out 된다.</li>
    <li>blocked 상태는 다른 I/O를 기다리는 상태이기 때문에 스스로 ready 상태로 돌아갈 수 있지만, suspend 상태는 외부적인 이유로 suspending 되었기 때문에 스스로 돌아갈 수 없다.</li>
  </ul>
</blockquote>

<h4 id="4-cpu-스케줄러"><strong>4. CPU 스케줄러</strong></h4>

<h5 id="41-fcfsfirst-come-first-served"><strong>4.1. FCFS(First Come First Served)</strong></h5>

<p>(1) 특징</p>

<ul>
  <li>먼저 온 순서대로 처리</li>
  <li>비선점형(Non-preemptive) 스케줄링</li>
</ul>

<blockquote>
  <p><em><strong>※ 선점형(Preemptive) 스케줄링</strong></em></p>

  <ul>
    <li>현재 수행 중인 프로세스의 남은 burst 시간보다 더 짧은 CPU burst 시간을 갖는 새로운 프로세스가 도착하면, CPU를 빼앗긴다.</li>
    <li>더 높은 우선순위의 프로세스가 도착하면, 실행 중인 프로세스를 멈추고 CPU를 선점한다.</li>
  </ul>
</blockquote>

<blockquote>
  <p><em><strong>※ 비선점형(Non-preemptive) 스케줄링</strong></em></p>

  <ul>
    <li>일단 CPU를 잡으면 CPU burst가 완료될 때까지 CPU를 반환하지 않는다.</li>
    <li>할당되었던 CPU가 반환될 때만 스케줄링이 이루어진다.</li>
    <li>더 높은 우선순위의 프로세스가 도착하면, Ready Queue의 head에 넣는다.</li>
  </ul>
</blockquote>

<p>(2) 문제점</p>

<ul>
  <li>convoy effect 발생
    <ul>
      <li>소요 시간이 긴 프로세스가 먼저 도달하여 시간을 잡아 먹고 있는 바람에 효율성이 떨어지는 현상 발생</li>
    </ul>
  </li>
</ul>

<h5 id="42-sjfshortest-job-first"><strong>4.2. SJF(Shortest Job First)</strong></h5>

<p>(1) 특징</p>

<ul>
  <li>다른 프로세스가 먼저 도착했어도, CPU burst 시간이 짧은 프로세스에게 먼저 할당된다.</li>
  <li>비선점형(Non-preemptive) 스케줄링</li>
</ul>

<p>(2) 문제점</p>

<ul>
  <li>starvation 발생
    <ul>
      <li>우선순위가 낮은 프로세스가 우선순위가 높은 프로세스가 있는 한은 절대 실행하지 못하고 무한정 기다리게 되는 현상</li>
      <li>특정 프로세스가 지나치게 차별받게 된다.</li>
      <li>CPU 사용량이 짧은 job을 극단적으로 소요하기 때문에, 사용 시간이 긴 프로세스는 영원히 CPU를 할당받을 수 없다.</li>
    </ul>
  </li>
</ul>

<h5 id="43-srtfshortest-remaining-time-first"><strong>4.3. SRTF(Shortest Remaining Time First)</strong></h5>

<p>(1) 특징</p>

<ul>
  <li>새로운 프로세스가 도착할 때 마다 새로운 스케줄링이 이루어진다.</li>
  <li>선점형(Preemptive) 스케줄링</li>
</ul>

<p>(2) 문제점</p>

<ul>
  <li>starvation</li>
  <li>새로운 프로세스가 도착할 때 마다 스케줄링을 다시 하기 때문에 CPU burst 시간을 측정할 수 없다.</li>
</ul>

<h5 id="44-priority-scheduling"><strong>4.4. Priority Scheduling</strong></h5>

<p>(1) 특징</p>

<ul>
  <li>우선순위가 가장 높은 프로세스에게 CPU를 할당하는 방법</li>
  <li>우선순위는 정수로 표현되고, 숫자가 작을 수록 우선순위가 높다.</li>
  <li>선점형(Preemptive) 스케줄링/비선점형(Non-preemptive) 스케줄링</li>
</ul>

<p>(2) 문제점</p>

<ul>
  <li>starvation</li>
  <li>무기한 봉쇄(Indefinite Blocking)
    <ul>
      <li>실행 준비는 되어 있으나, CPU를 사용하지 못하는 프로세스가 무기한 대기하는 상태</li>
    </ul>
  </li>
</ul>

<p>(3) 해결책</p>

<ul>
  <li>aging
    <ul>
      <li>아무리 우선순위가 낮은 프로세스라도 오래 기다리면 우선 순위를 높여주는 방법</li>
    </ul>
  </li>
</ul>

<h5 id="45-rrround-robin"><strong>4.5. RR(Round Robin)</strong></h5>

<p>(1) 특징</p>

<ul>
  <li>현대적인 CPU 스케줄링 방법</li>
  <li>각 프로세는 동일한 크기의 할당 시간(time quantum)을 갖게 된다.
    <ul>
      <li>할당 시간이 지나면 프로세스는 선점당하고, ready Queue의 제일 뒤에 가서 다시 줄을 선다.</li>
    </ul>
  </li>
  <li>CPU 사용 시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적이다.</li>
  <li>프로세스들의 context를 저장할 수 있기 때문에 이러한 스케줄링이 가능하다.</li>
</ul>

<p>(2) 장점</p>

<ul>
  <li>응답 시간이 빨라진다.</li>
  <li>어떠한 프로세스도 (n-1)q time 단위 이상 기다리지 않는다.
    <ul>
      <li>n개의 프로세스가 ready queue에 있고 할당 시간이 q인 경우, 각 프로세스는 q 단위로 CPU 시간의 1/n을 얻는다.</li>
    </ul>
  </li>
  <li>프로세스가 기다리는 시간이 CPU를 사용할 만큼 증가한다(공정한 스케줄링).</li>
</ul>

<p>(3) 주의점</p>

<ul>
  <li>적절한 time quantum 설정
    <ul>
      <li>time quantum이 너무 커지는 경우: FCFS와 같아진다.</li>
      <li>time quantum이 너무 작아지는 경우: 스케줄링 알고리즘 목적에는 이상적이지만, 작은 context switch로 overhead가 발생한다.</li>
    </ul>
  </li>
</ul>

<h4 id="5-동기와-비동기의-차이"><strong>5. 동기와 비동기의 차이</strong></h4>

<p>(출처: <a href="https://asfirstalways.tistory.com/348">https://asfirstalways.tistory.com/348</a>)</p>

<h5 id="51-sync-vs-async"><strong>5.1. Sync vs. Async</strong></h5>

<ul>
  <li>동기: 메소드를 실행시킴과 동시에 반환값이 기대되는 경우</li>
  <li>비동기: 메소드를 실행시킴과 동시에 반환값이 기대되지 않는 경우</li>
</ul>

<h5 id="52-blocking-io-model"><strong>5.2. Blocking I/O Model</strong></h5>

<p><img src="https://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/files/06fig01.gif" alt="Alt text" /> <br />
(출처: <a href="https://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/ch06lev1sec2.html">https://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/ch06lev1sec2.html</a>)</p>

<ul>
  <li>일단 I/O 작업은 User Level(application)에서 직접 수행할 수 없다.
    <ul>
      <li>실제 I/O 작업은 Kernel level(OS)에서 일어나는 과정이다.</li>
      <li>유저 프로세스(application)는 커널(OS)에게 I/O 작업에 대한 요청을 해야 한다.</li>
    </ul>
  </li>
  <li>I/O 작업 처리를 위해 User level에 있던 application이 시스템 함수를 호출한다(System call).
    <ul>
      <li>이 때, context switching이 일어난다.</li>
      <li>그리고 kernel level에서 해당 I/O 작업이 끝나고 데이터를 반환하게 되면, 그 때가 되서야 애플리케이션 단의 스레드에 걸렸던 block이 풀리게 된다.</li>
    </ul>
  </li>
  <li>application 관점에서 보면 아무런 동작도 안하는 것처럼 보이지만, 실제로는 커널에서 I/O 작업을 수행하느라 block 되어 있는 것이다.
    <ul>
      <li>blocking I/O의 문제점이며, 개선 포인트이다.</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><em><strong>※ Synchronous, Blocking I/O의 비교</strong></em></p>

  <ol>
    <li>Synchronous
      <ul>
        <li>작업을 요청한 후 해당 작업의 결과가 나올 때까지 기다린 후 처리한다.</li>
        <li>I/O 작업에 대한 readiness를 기다린다.</li>
        <li>특정 I/O 작업을 하기 위한 준비가 되었는 지에 집중하는 것</li>
        <li>I/O 작업 준비에 대한 이벤트 발생을 기다렸다가 해당 이벤트가 발생하면, 그에 따른 적합한 처리를 한다.</li>
      </ul>
    </li>
    <li>Blocking I/O
      <ul>
        <li>I/O가 끝날 때까지 대기해야 한다.
          <ul>
            <li>끝나기 전 까지는 함수가 반환(return)되지 않기 때문</li>
          </ul>
        </li>
        <li>커널이 작업을 완료하기 전까지 유저 프로세스는 작업을 중단한 채 대기해야 한다.</li>
        <li>I/O 작업이 CPU 자원을 거의 쓰지 않기 때문에 blocking 방법은 CPU 자원 낭비가 심하다.
          <ul>
            <li>동기화 하기 위해 blocking 하는 것</li>
          </ul>
        </li>
      </ul>
    </li>
    <li>Synchronous vs. Blocking I/O
      <ul>
        <li>둘 다 시스템의 반환을 기다린다는 측면에서는 같은 개념
          <ul>
            <li>Synchronous: 시스템 반환을 기다리는 동안 대기 큐에 머무는 것이 필수가 아님</li>
            <li>Blocking I/O: 시스템 반환을 기다리는 동안 대기 큐에 머무는 것이 필수</li>
          </ul>
        </li>
      </ul>
    </li>
  </ol>
</blockquote>

<h5 id="53-non-blocking-io-model"><strong>5.3. Non-Blocking I/O Model</strong></h5>

<p><img src="https://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/files/06fig02.gif" alt="Alt text" /> <br />
(출처: <a href="https://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/ch06lev1sec2.html">https://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/ch06lev1sec2.html</a>)</p>

<ul>
  <li>I/O 작업을 진행하는 동안 유저 프로세스의 작업을 중단시키지 않는다.</li>
  <li>유저 프로세스가 I/O를 처리하기 위해 커널에 함수를 호출(System call)하면, 커널에서 함수의 진행사항과 상관없이 바로 결과를 반환한다.
    <ul>
      <li>반환되는 결과 = 반환하는 순간에 가져올 수 있는 데이터</li>
    </ul>
  </li>
  <li>이렇게 되면 서버는 클라이언트가 요청한 사이즈에 맞는 데이터를 반환하게 위해 데이터를 축적해야 한다.
    <ul>
      <li>데이터의 축적이 끝났을 때 반환되어 클라이언트에서 요청한 사이즈의 데이터를 받아올 수 있게 된다.</li>
    </ul>
  </li>
  <li>이 구현의 문제점: 클라이언트가 따로 반환되는 값이 원하는 사이즈가 되었는 지 계속 확인해야 한다는 것(polling)
    <ul>
      <li>반환되는 데이터가 준비되었는 지 확인하는 과정에서 수많은 클라이언트의 요청이 동시다발적으로 일어날 경우, CPU에게 적지 않는 부담이 된다.</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><em><strong>※ Blocking vs. Non-blocking</strong></em></p>

  <ol>
    <li>Blocking
      <ul>
        <li>애플리케이션 실행 시, 운영체제 대기 큐에 들어가면서 요청에 대한 System call이 완료된 후 응답을 보내는 것</li>
      </ul>
    </li>
    <li>Non-blocking
      <ul>
        <li>애플리케이션 실행 시, 운영체제 대기 큐에 들어가지 않고 실행여부와 관계없이 바로 응답을 보내는 것</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h5 id="54-asynchronous-io-model"><strong>5.4. Asynchronous I/O Model</strong></h5>

<p><img src="https://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/files/06fig05.gif" alt="Alt text" /> <br />
(출처: <a href="https://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/ch06lev1sec2.html">https://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/ch06lev1sec2.html</a>)</p>

<p>(1) Event-driven Model</p>

<ul>
  <li>Non-blocking I/O model에서 제기된 문제를 해결하기 위해 고안되었다.
    <ul>
      <li>Non-blocking I/O model에서처럼 애플리케이션 데이터가 준비되었는 지 계속 확인(polling)하는 것이 아니라, kernel level에서 데이터가 준비되면, 콜백 또는 이벤트를 발생시켜 애플리케이션에게 알리게 된다(notify).</li>
      <li>User level에서 애플리케이션 스레드는 계속해서 데이터가 준비되었는 지 확인할 필요 없이 다음 작업을 수행하다가 커널에서 이벤틀가 발생하게 되면, 그 작업에 해당하는 일을 처리해주면 되는 것이다.</li>
    </ul>
  </li>
</ul>

<p>(2) Asynchronous</p>

<ul>
  <li>작업을 요청해놓고 딴 일을 하다가, 해당 작업이 완료되면 그 때 완료되었음을 통지받고(notify) 그에 따른 작업을 하는 것</li>
  <li>I/O 작업의 completion을 기다린다.</li>
  <li>운영체제 단계의 비동기 I/O를 통해 이루어지며, I/O 작업이 completion 되면, 그에 적합한 handler를 이용해 처리한다.</li>
</ul>

<blockquote>
  <p><em><strong>※ 정리</strong></em></p>

  <ol>
    <li>Synchronous vs. Asynchronous
      <ul>
        <li>Synchronous: System call의 완료를 기다림</li>
        <li>Asynchronous: Sytem call의 완료를 기다리지 않음</li>
      </ul>
    </li>
    <li>Non-blocking vs. Asynchronous
      <ul>
        <li>Non-blocking: System call이 반환될 때 실행된 결과(데이터)와 함께 반환</li>
        <li>Asynchronous: System call이 반환될 때 실행된 결과(데이터)와 함께 반환되지 않음</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h4 id="6-cpu-스케줄러"><strong>6. CPU 스케줄러</strong></h4>

<h5 id="61-critical-section임계영역"><strong>6.1. Critical Section(임계영역)</strong></h5>

<ul>
  <li>
    <p>동일한 자원을 동시에 접근하는 작업(e.g. 공유하는 변수 사용, 동일 파일을 사용하는 것 등)을 실행하는 코드 영역</p>
  </li>
  <li>
    <p>공유 데이터를 동시에 접근하는 코드 영역</p>
    <ul>
      <li>공유 데이터: 여러 프로세스들이 서로 공유할 수 있는 데이터</li>
    </ul>
  </li>
</ul>

<h5 id="62-critical-section-problem임계영역-문제"><strong>6.2. Critical Section Problem(임계영역 문제)</strong></h5>

<p>(1) 임계영역 문제란?</p>

<ul>
  <li>
    <p>프로세스들이 Critical Section을 함께 사용할 수 있는 프로토콜을 설계하는 것
(2) 해결을 위한 기본 조건</p>
  </li>
  <li>Mutual Exclusion(상호 배제)
    <ul>
      <li>프로세스 P1이 Critical Section에서 실행 중이라면, 다른 프로세스들은 P1이 가진 Critical Section에서 실행될 수 없다.</li>
      <li>둘 이상의 프로세스가 동시에 공유데이터에 진입하는 것을 막는 것</li>
    </ul>
  </li>
  <li>Progress(진행)
    <ul>
      <li>Critical Section에서 실행 중인 프로세스가 없고 별도의 동작이 없는 프로세스들만 Critical Section 진입 후보로서 참여될 수 있다.</li>
    </ul>
  </li>
  <li>Bounded Waiting(한정된 대기)
    <ul>
      <li>프로세스 P1이 Critical Section에 진입 신청한 후 부터 받아들여 질 때 까지, 다른 프로세스들이 Critical Section에 진입하는 횟수는 제한이 있어야 한다.</li>
    </ul>
  </li>
</ul>

<h5 id="63-critical-section-problem의-해결책"><strong>6.3. Critical Section Problem의 해결책</strong></h5>

<p>(1) Lock</p>

<ul>
  <li>특징
    <ul>
      <li>하드웨어 기반의 해결책</li>
      <li>동시에 공유자원에 접근하는 것을 막기 위해, Critical Section에 진입하는 프로세스는 Lock을 획득하고, Critical Section을 빠져 나올 때, Lock을 방출함으로써 동시에 공유 자원에 접근하지 않도록 한다.</li>
    </ul>
  </li>
  <li>한계
    <ul>
      <li>다중 처리기 환경에서는 시간적인 효율성 측면에서 적용할 수 없다.</li>
    </ul>
  </li>
</ul>

<p>(2) Semaphores(세마포어)</p>

<ul>
  <li>특징
    <ul>
      <li>소프트웨어 상에서 Critical Section 문제를 해결하기 위한 도구</li>
    </ul>
  </li>
  <li>종류(OS는 Counting/Binary 세마포어를 구분함)
    <ul>
      <li>Counting 세마포어
        <ul>
          <li>가용한 개수를 가진 자원에 대한 접근 제어용으로 사용되며, 세마포어는 가용한 자원의 개수로 초기화된다.</li>
          <li>자원을 사용하면 세마포어가 감소하고, 자원을 방출하면 세마포어는 증가한다.</li>
        </ul>
      </li>
      <li>Binary 세마포어
        <ul>
          <li>Mutex라고도 부르며, 상호배제(Mutex Exclusion)의 머릿글자를 따서 만들어졌다.</li>
          <li>이름 그대로 0과 1 사이의 값만 가능</li>
          <li>다중 프로세스들 사이의 Critical Section 문제를 해결하기 위해 사용</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>단점
    <ul>
      <li>Busy Wating(바쁜 대기)
        <ul>
          <li>Spin Lock 이라고 불리는 세마포어 초기 버전에서 Critical Section에 진입해야 하는 프로세스는 진입코드를 계속 반복 실행해야 하며, CPU 시간을 낭비했었다(특수한 상황이 아니면 비효율적).</li>
          <li>해결책: 일반적으로는 세마포어에서 Critical Section에 진입을 시도했지만 실패한 프로세스를 block 시킨 뒤, Critical Section에 자리가 날 때 다시 깨우는 방식을 사용</li>
        </ul>
      </li>
      <li>Deadlock(교착상태)
        <ul>
          <li>세마포어가 Ready Queue를 가지고 있고 둘 이상의 프로세스가 Critical Section에 진입하려고 무한정 기다리고 있을 때, Critical Section에서 실행되는 프로세스는 진입 대기중인 프로세스가 실행되어야만 빠져나올 수 있는 상황</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>(3) 모니터</p>

<ul>
  <li>고급 언어의 설계 구조물로서, 개발자의 코드를 상호배제 하게 끔 만든 추상화된 데이터 형태</li>
  <li>공유자원에 접근하기 위한 키 획득과 자원 사용 후 해제를 모두 처리한다(세마포어는 직접 키 해제와 공유자원 접근 처리가 필요).</li>
</ul>

<h4 id="7-메모리-관리-전략"><strong>7. 메모리 관리 전략</strong></h4>

<h5 id="71-메모리-관리-배경"><strong>7.1. 메모리 관리 배경</strong></h5>

<ul>
  <li>각각의 프로세스는 독립된 메모리 공간을 갖지만, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려 있다.
    <ul>
      <li>운영체제만이 운영체제 메모리 영역과 사용자 메모리 영역에 접근하는 것에 제약을 받지 않는다.</li>
    </ul>
  </li>
</ul>

<p>(1) Swapping</p>

<ul>
  <li>
    <p>메모리 관리를 위해 사용되는 기법</p>
  </li>
  <li>
    <p>Swap이란?</p>
    <ul>
      <li>표준 Swapping 방식으로는 round-robin과 같은 스케줄링의 다중 프로그래밍 환경에서, CPU 할당 시간이 끝난 프로세스의 메모리를 보조 기억장치(e.g. 하드 디스크)로 보내고, 다른 프로세스의 메모리를 불러들일 수 있다.
        <ul>
          <li>swap-in: 주 기억장치(RAM)으로 불러오는 과정</li>
          <li>swap-out: 보조 기억 장치로 내보내는 과정</li>
        </ul>
      </li>
      <li>swap에는 큰 디스크 전송 시간이 필요하기 때문에 현재에는 메모리 공간이 부족할 때 swapping이 시작된다.</li>
    </ul>
  </li>
</ul>

<h5 id="72-메모리-단편화memory-fragmentation"><strong>7.2. 메모리 단편화(Memory Fragmentation)</strong></h5>

<ul>
  <li>
    <p>메모리 관리 시 발생하는 문제</p>
  </li>
  <li>
    <p>프로세스들이 메모리에 적재되고 제거되는 일이 반복되다 보면 프로세스들이 차지하는 메모리 틈 사이에 사용하지 못 할 만큼의 작은 자유 공간들이 늘어나게 되는 현상</p>
  </li>
  <li>외부 단편화
    <ul>
      <li>메모리 공간 중 사용하지 못하게 되는 일부분</li>
      <li>물리 메모리(RAM)에서 사이사이 남는 공간들을 모두 합치면 충분한 공간이 되는 부분들이 분산되어 있을 때 발생</li>
      <li>해결책: 압축작업
        <ul>
          <li>외부 단편화를 해소하기 위해 프로세스가 사용하는 공간들을 한 쪽으로 몰아 자유공간을 확보하는 방법론(작업 효율이 좋지 않음)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>내부 단편화
    <ul>
      <li>프로세스가 사용하는 메모리 공간에 포함된 남는 부분
        <ul>
          <li>메모리 분할 자유공간이 10,000B가 있고 Process A가 9,998B 사용하게 되면, 2B라는 차이가 존재하게 됨</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="73-메모리-단편화fragmentation-문제-해결책"><strong>7.3. 메모리 단편화(Fragmentation) 문제 해결책</strong></h5>

<p>(1) paging</p>

<ul>
  <li>특징
    <ul>
      <li>하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 없애는 메모리 관리 방법</li>
      <li>외부 단편화의 압축작업을 해소하기 위해 생긴 방법론</li>
      <li>물리 메모리는 Frame이라는 고정 크기로 분리되어 있고, 논리 메모리(프로세스가 점유하는)는 페이지라 불리는 고정 크기의 블록으로 분리된다.</li>
      <li>하나의 프로세스가 사용하는 공간은 논리메모리에서 여러 개의 페이지로 나뉘어서 관리되고, 개별 페이지는 순서에 상관없이 물리 메모리에 있는 프레임에 mapping 되어 저장된다고 볼 수 있다.</li>
    </ul>
  </li>
  <li>장점
    <ul>
      <li>페이징 기법을 사용함으로써, 논리 메모리는 물리 메모리에 저장될 때 연속해서 저장될 필요 없고, 물리 메모리의 남는 프레임에 적절히 배치됨으로써 외부 단편화를 해결할 수 있다.</li>
    </ul>
  </li>
  <li>단점
    <ul>
      <li>내부 단편화 문제의 비중이 늘어난다.</li>
      <li>페이지의 크기가 1,024B이고 프로세스 A가 3,172B의 메모리를 요구한다면, 3개의 페이지 프레임(1024 * 3 = 3072) 하고도 100B가 필요하다
        <ul>
          <li>총 4개의 페이지 프레임이 필요하며, 4번째 프레임에는 924B(1024-100)의 여유 공간이 생기는 문제가 발생한다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>(2) Segmentation</p>

<ul>
  <li>특징
    <ul>
      <li>페이징에서처럼 논리 메모리와 물리 메모리는 같은 크기의 블록이 아닌, 서로 다른 크기의 논리적 단위인 세그먼트(Segment)로 분할</li>
      <li>사용자가 두개의 주소로 지정(세그먼트 번호 + 변위)</li>
      <li>세그먼트 테이블에는 각 세그먼트 기준(세그먼트 시작 물리 주소)과 한계(세그먼트 길이)를 저장</li>
    </ul>
  </li>
  <li>단점
    <ul>
      <li>외부 단편화 문제 발생
        <ul>
          <li>서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되면, 자유 공간들이 많은 수의 조각들로 나뉘어져 못 쓰게 될 수도 있다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>(3) 메모리 풀(Pool)</p>

<ul>
  <li>특징
    <ul>
      <li>필요한 메모리 공간을 필요한 크기, 개수만큼 사용자가 직접 지정하여 미리 할당받아 놓고 필요할 때마다 사용하고 반납하는 기법</li>
      <li>메모리의 할당, 해제가 잦은 경우에 효과적</li>
    </ul>
  </li>
  <li>장점
    <ul>
      <li>외부 단편화가 발생하지 않음
        <ul>
          <li>메모리 풀 없이 동적할당과 해제를 반복하면 메모리의 랜덤한(실제로는 알고리즘에 의한) 위치에 할당과 해제가 반복되면서 단편화를 일으킬 수 있겠지만, 미리 공간을 할당해놓고 가져다 쓴 후 반납하기 때문에 할당과 해제로 인한 외부 단편화가 발생하지 않는다.</li>
        </ul>
      </li>
      <li>내부 단편화가 발생하지 않음
        <ul>
          <li>필요한 크기만큼 할당을 해놓기 때문에 내부 단편화가 발생하지 않는다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>단점
    <ul>
      <li>메모리 단편화로 인한 메모리 낭비량보다 메모리 풀을 만들었지만 쓰지 않았을 때 메모리의 양이 커진다면 사용하지 않아야 한다.</li>
      <li>미리 할당해놓고 사용하지 않을 때에도 계속 할당 해 놓기 때문에 메모리 누수 발생</li>
    </ul>
  </li>
</ul>

<p>참고: <a href="https://github.com/JaeYeopHan/Interview_Question_for_Beginner">https://github.com/JaeYeopHan/Interview_Question_for_Beginner</a></p>

  </div>

  <a class="u-url" href="/CS-OS" hidden></a>
</article>

<script>
  $(document).ready(function() {
    $('.highlighter-rouge div.highlight').prepend('<i class="fas fa-code code-block"></i>');
  })
</script>

      </div>
    </main>
    <script src="/assets/js/jquery-3.6.0.min.js" />
  </body>

</html>
